<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kafka-knative-amp-setup</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; line-height: 1.6; }
        pre { background: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; }
        code { background: #f5f5f5; padding: 2px 4px; border-radius: 3px; }
        pre code { background: none; padding: 0; }
        blockquote { border-left: 4px solid #ddd; margin: 0; padding-left: 20px; color: #666; }
        h1, h2, h3 { color: #333; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <h1>End-to-End Installation &amp; Validation Guide</h1>
<p><em>Complete setup and testing for Prometheus Agent → Amazon Managed Prometheus (AMP) → Grafana dashboards for Knative &amp; Kafka</em></p>
<p><img src="https://github.com/user-attachments/assets/e8b7b32e-cb26-4488-a15a-96d7626c233c" alt="image"></p>
<hr>
<h2>1 Prerequisites &amp; Environment Validation</h2>
<h3>1.1 Required Components</h3>
<ul>
<li><strong>EKS cluster</strong> (≥ 1.24) with OIDC provider enabled</li>
<li><strong>Command line tools</strong>: <code>helm</code> ≥ 3.10, <code>kubectl</code>, <code>jq</code>, and AWS CLI v2</li>
<li><strong>AWS Resources</strong>: <ul>
<li>AMP workspace (e.g., <code>&lt;AMP_WORKSPACE_ID&gt;</code>)</li>
<li>Grafana instance with AMP integration</li>
</ul>
</li>
<li><strong>Kafka cluster</strong>: MSK, Strimzi, or other Kafka deployment reachable from EKS nodes</li>
<li><strong>Knative</strong>: Serving and/or Eventing components installed</li>
</ul>
<h3>1.2 Validate Prerequisites</h3>
<pre><code class="language-bash"># Check EKS cluster and OIDC
aws eks describe-cluster --name &lt;your-cluster-name&gt; --query &#39;cluster.identity.oidc.issuer&#39;

# Verify command line tools
helm version --short
kubectl version --client --short
jq --version
aws --version

# Install awscurl for querying AMP (required for testing)
pip install awscurl

# Check AMP workspace exists
aws amp describe-workspace --workspace-id &lt;AMP_WORKSPACE_ID&gt; --region &lt;YOUR_AWS_REGION&gt;

# Verify Knative components
kubectl get pods -n knative-serving
kubectl get pods -n knative-eventing

# Check Kafka accessibility (replace with your Kafka endpoints)
kubectl run kafka-test --rm -it --restart=Never --image=confluentinc/cp-kafka:latest -- \
  kafka-topics --bootstrap-server &lt;your-kafka-broker&gt;:9092 --list
</code></pre>
<hr>
<h2>2 Create IRSA Role for AMP Integration</h2>
<h3>2.1 Gather Required Information</h3>
<pre><code class="language-bash"># Get your AWS account ID
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Get your EKS cluster&#39;s OIDC issuer
OIDC_ISSUER=$(aws eks describe-cluster --name &lt;your-cluster-name&gt; --query &#39;cluster.identity.oidc.issuer&#39; --output text)
OIDC_ID=$(echo $OIDC_ISSUER | cut -d&#39;/&#39; -f5)

echo &quot;Account ID: $AWS_ACCOUNT_ID&quot;
echo &quot;OIDC ID: $OIDC_ID&quot;
</code></pre>
<h3>2.2 Create IAM Role and Policy</h3>
<pre><code class="language-bash"># Create the IAM policy
cat &gt; amp-ingest-policy.json &lt;&lt; EOF
{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: [
        &quot;aps:RemoteWrite&quot;,
        &quot;aps:GetSeries&quot;,
        &quot;aps:GetLabels&quot;,
        &quot;aps:GetMetricMetadata&quot;
      ],
      &quot;Resource&quot;: &quot;arn:aws:aps:&lt;YOUR_AWS_REGION&gt;:$AWS_ACCOUNT_ID:workspace/&lt;AMP_WORKSPACE_ID&gt;&quot;
    }
  ]
}
EOF

aws iam create-policy --policy-name EKS-AMP-Ingest-Policy --policy-document file://amp-ingest-policy.json

# Create the trust policy
cat &gt; amp-trust-policy.json &lt;&lt; EOF
{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;Federated&quot;: &quot;arn:aws:iam::$AWS_ACCOUNT_ID:oidc-provider/oidc.eks.&lt;YOUR_AWS_REGION&gt;.amazonaws.com/id/$OIDC_ID&quot;
      },
      &quot;Action&quot;: &quot;sts:AssumeRoleWithWebIdentity&quot;,
      &quot;Condition&quot;: {
        &quot;StringEquals&quot;: {
          &quot;oidc.eks.&lt;YOUR_AWS_REGION&gt;.amazonaws.com/id/$OIDC_ID:sub&quot;: &quot;system:serviceaccount:monitoring:amp-iamproxy-ingest&quot;
        }
      }
    }
  ]
}
EOF

# Create the IAM role
aws iam create-role --role-name EKS-AMP-Ingest --assume-role-policy-document file://amp-trust-policy.json

# Attach the policy to the role
aws iam attach-role-policy --role-name EKS-AMP-Ingest --policy-arn arn:aws:iam::$AWS_ACCOUNT_ID:policy/EKS-AMP-Ingest-Policy
</code></pre>
<h3>2.3 Create ServiceAccount</h3>
<pre><code class="language-bash"># Create the monitoring namespace
kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

# Create the ServiceAccount with IRSA annotation
cat &gt; amp-serviceaccount.yaml &lt;&lt; EOF
apiVersion: v1
kind: ServiceAccount
metadata:
  name: amp-iamproxy-ingest
  namespace: monitoring
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::$AWS_ACCOUNT_ID:role/EKS-AMP-Ingest
EOF

kubectl apply -f amp-serviceaccount.yaml
</code></pre>
<h3>2.4 Validate IRSA Setup</h3>
<pre><code class="language-bash"># Check ServiceAccount annotation
kubectl get sa amp-iamproxy-ingest -n monitoring -o yaml

# Test role assumption (should show assumed role ARN)
kubectl run irsa-test --rm -it --restart=Never --serviceaccount=amp-iamproxy-ingest --namespace=monitoring --image=amazon/aws-cli:latest -- \
  sts get-caller-identity
</code></pre>
<hr>
<h2>3 Install Prometheus Agent with Helm</h2>
<h3>3.1 Add Helm Repository</h3>
<pre><code class="language-bash">helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
</code></pre>
<h3>3.2 Install Prometheus Agent</h3>
<pre><code class="language-bash"># Replace these values with your actual cluster name and workspace ID
CLUSTER_NAME=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;
WORKSPACE_ID=&quot;&lt;AMP_WORKSPACE_ID&gt;&quot;
AWS_REGION=&quot;&lt;YOUR_AWS_REGION&gt;&quot;

helm upgrade --install amp-agent prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace \
  --set prometheus.serviceAccount.create=false \
  --set prometheus.serviceAccount.name=amp-iamproxy-ingest \
  --set prometheus.prometheusSpec.serviceAccountName=amp-iamproxy-ingest \
  --set prometheus.prometheusSpec.mode=agent \
  --set prometheus.prometheusSpec.enableRemoteWriteReceiver=false \
  --set prometheus.prometheusSpec.externalLabels.cluster=$CLUSTER_NAME \
  --set-string &quot;prometheus.prometheusSpec.remoteWrite[0].url=https://aps-workspaces.$AWS_REGION.amazonaws.com/workspaces/$WORKSPACE_ID/api/v1/remote_write&quot; \
  --set &quot;prometheus.prometheusSpec.remoteWrite[0].sigv4.region=$AWS_REGION&quot; \
  --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
  --set-json prometheus.prometheusSpec.serviceMonitorSelector=&#39;{}&#39; \
  --set-json prometheus.prometheusSpec.serviceMonitorNamespaceSelector=&#39;{}&#39; \
  --set prometheusOperator.serviceMonitor.selfNamespace=true \
  --set prometheus.prometheusSpec.scrapeInterval=30s \
  --set &#39;prometheus.prometheusSpec.remoteWrite[0].queueConfig.maxSamplesPerSend=1000&#39; \
  --set &#39;prometheus.prometheusSpec.remoteWrite[0].queueConfig.batchSendDeadline=30s&#39; \
  --set &#39;prometheus.prometheusSpec.remoteWrite[0].queueConfig.maxShards=200&#39; \
  --set &#39;prometheus.prometheusSpec.remoteWrite[0].queueConfig.capacity=5000&#39;
</code></pre>
<h3>3.3 Verify Prometheus Agent Installation</h3>
<pre><code class="language-bash"># Check if pods are running
kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus

# Check agent logs (look for successful startup)
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus --tail=20

# Verify ServiceAccount is being used
kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus -o yaml | grep -A2 -B2 serviceAccount
</code></pre>
<hr>
<h2>4 Deploy Knative ServiceMonitors</h2>
<h3>4.1 Install Knative Monitoring Components</h3>
<pre><code class="language-bash"># Install Knative monitoring ServiceMonitors
kubectl apply -f https://raw.githubusercontent.com/knative-extensions/monitoring/main/servicemonitor.yaml

# Verify ServiceMonitors were created
kubectl get servicemonitor -A | grep knative
</code></pre>
<h3>4.2 Validate Knative Metrics Endpoints</h3>
<pre><code class="language-bash"># Check if Knative pods expose metrics
kubectl get pods -n knative-serving -o wide
kubectl get pods -n knative-eventing -o wide

# Test metrics endpoint on a Knative pod (replace POD_NAME)
kubectl exec -n knative-serving &lt;POD_NAME&gt; -- curl -s localhost:9090/metrics | head -10

# Or port-forward to test locally
kubectl port-forward -n knative-serving &lt;POD_NAME&gt; 9090:9090 &amp;
curl -s localhost:9090/metrics | grep -E &quot;knative_|serving_|eventing_&quot; | head -5
</code></pre>
<hr>
<h2>5 Deploy kafka-exporter and ServiceMonitor</h2>
<h3>5.1 Create Kafka Credentials Secret</h3>
<pre><code class="language-bash"># Create secret for Kafka authentication (adjust based on your setup)
kubectl create secret generic kafka-secret \
  --from-literal=user=&lt;your-kafka-username&gt; \
  --from-literal=password=&lt;your-kafka-password&gt; \
  --namespace=monitoring

# For MSK with IAM authentication, you might not need username/password
# Instead, use IAM roles for service accounts
</code></pre>
<h3>5.2 Deploy kafka-exporter</h3>
<pre><code class="language-yaml"># kafka-exporter.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-exporter
  namespace: monitoring
  labels: 
    app: kafka-exporter
    component: metrics
spec:
  replicas: 1
  selector:
    matchLabels: 
      app: kafka-exporter
  template:
    metadata:
      labels: 
        app: kafka-exporter
        component: metrics
    spec:
      containers:
      - name: kafka-exporter
        image: danielqsj/kafka-exporter:v1.7.0
        args:
          # Replace with your actual Kafka broker endpoints
          - &#39;--kafka.server=&lt;KAFKA_BROKER_1&gt;&#39;
          - &#39;--kafka.server=&lt;KAFKA_BROKER_2&gt;&#39;
          - &#39;--kafka.server=&lt;KAFKA_BROKER_3&gt;&#39;
          - &#39;--sasl.enabled&#39;
          - &#39;--sasl.username=$(KAFKA_USERNAME)&#39;
          - &#39;--sasl.password=$(KAFKA_PASSWORD)&#39;
          - &#39;--sasl.mechanism=scram-sha512&#39;
          - &#39;--tls.enabled&#39;
          - &#39;--tls.insecure-skip-tls-verify&#39;
          - &#39;--kafka.version=&lt;KAFKA_VERSION&gt;&#39;
          - &#39;--web.listen-address=:9308&#39;
          - &#39;--log.level=info&#39;
        env:
          - name: KAFKA_USERNAME
            valueFrom: 
              secretKeyRef: 
                name: kafka-secret
                key: user
          - name: KAFKA_PASSWORD
            valueFrom: 
              secretKeyRef: 
                name: kafka-secret
                key: password
        ports:
          - name: metrics
            containerPort: 9308
            protocol: TCP
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9308
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9308
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          requests:
            memory: &quot;64Mi&quot;
            cpu: &quot;50m&quot;
          limits:
            memory: &quot;128Mi&quot;
            cpu: &quot;100m&quot;
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-exporter
  namespace: monitoring
  labels: 
    app: kafka-exporter
    component: metrics
spec:
  type: ClusterIP
  ports:
    - name: metrics
      port: 9308
      targetPort: 9308
      protocol: TCP
  selector:
    app: kafka-exporter
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kafka-exporter
  namespace: monitoring
  labels:
    app: kafka-exporter
    component: metrics
spec:
  selector:
    matchLabels:
      app: kafka-exporter
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s
      honorLabels: true
  namespaceSelector:
    matchNames:
      - monitoring
</code></pre>
<h3>5.3 Apply kafka-exporter Configuration</h3>
<pre><code class="language-bash"># Apply the complete kafka-exporter setup
kubectl apply -f kafka-exporter.yaml

# Check deployment status
kubectl get deployment kafka-exporter -n monitoring
kubectl get pods -n monitoring -l app=kafka-exporter

# Check service and endpoints
kubectl get svc kafka-exporter -n monitoring
kubectl get endpoints kafka-exporter -n monitoring
</code></pre>
<hr>
<h2>6 Comprehensive kafka-exporter Testing</h2>
<h3>6.1 Basic Connectivity Tests</h3>
<pre><code class="language-bash"># Check if kafka-exporter pod is running
kubectl get pods -n monitoring -l app=kafka-exporter -o wide

# Check pod logs for any errors
kubectl logs -n monitoring -l app=kafka-exporter --tail=20

# Test if the metrics endpoint is accessible
kubectl exec -n monitoring -l app=kafka-exporter -- curl -s localhost:9308/metrics | head -10
</code></pre>
<h3>6.2 Port-Forward and Web Interface Testing</h3>
<pre><code class="language-bash"># Port-forward to access kafka-exporter web interface
kubectl port-forward -n monitoring svc/kafka-exporter 9308:9308 &amp;

# Test metrics endpoint locally
curl -s localhost:9308/metrics | head -20

# Access the web interface (open in browser)
echo &quot;Open http://localhost:9308 in your browser to see kafka-exporter web interface&quot;

# Test specific metric queries
curl -s localhost:9308/metrics | grep -E &quot;kafka_brokers|kafka_topic_partitions|kafka_consumergroup_lag&quot;

# Check for specific Kafka metrics
curl -s localhost:9308/metrics | grep -c &quot;kafka_&quot; 
echo &quot;Total kafka metrics found: $(curl -s localhost:9308/metrics | grep -c &quot;kafka_&quot;)&quot;
</code></pre>
<h3>6.3 Kafka Connection Validation</h3>
<pre><code class="language-bash"># Check if kafka-exporter can connect to Kafka brokers
kubectl logs -n monitoring -l app=kafka-exporter | grep -E &quot;connecting|connected|error|failed&quot;

# Look for successful broker connections
kubectl logs -n monitoring -l app=kafka-exporter | grep -i &quot;broker&quot;

# Check for authentication success
kubectl logs -n monitoring -l app=kafka-exporter | grep -i &quot;auth&quot;
</code></pre>
<h3>6.4 Metrics Quality Tests</h3>
<pre><code class="language-bash"># Test for essential Kafka metrics
METRICS_ENDPOINT=&quot;localhost:9308&quot;

echo &quot;Testing essential Kafka metrics...&quot;

# Broker metrics
echo &quot;Broker metrics:&quot;
curl -s http://$METRICS_ENDPOINT/metrics | grep &quot;kafka_brokers{&quot; | head -3

# Topic metrics
echo &quot;Topic metrics:&quot;
curl -s http://$METRICS_ENDPOINT/metrics | grep &quot;kafka_topic_partitions{&quot; | head -3

# Consumer group lag (critical for monitoring)
echo &quot;Consumer group lag metrics:&quot;
curl -s http://$METRICS_ENDPOINT/metrics | grep &quot;kafka_consumergroup_lag{&quot; | head -3

# Partition metrics
echo &quot;Partition metrics:&quot;
curl -s http://$METRICS_ENDPOINT/metrics | grep &quot;kafka_partition_&quot; | head -3

# Count total metrics
echo &quot;Total metrics exposed:&quot;
curl -s http://$METRICS_ENDPOINT/metrics | grep -E &quot;^kafka_&quot; | wc -l
</code></pre>
<h3>6.5 ServiceMonitor Discovery Test</h3>
<pre><code class="language-bash"># Check if Prometheus can discover kafka-exporter ServiceMonitor
kubectl get servicemonitor kafka-exporter -n monitoring -o yaml

# Verify labels match between service and ServiceMonitor
kubectl get svc kafka-exporter -n monitoring -o yaml | grep -A5 &quot;labels:&quot;
kubectl get servicemonitor kafka-exporter -n monitoring -o yaml | grep -A5 &quot;matchLabels:&quot;
</code></pre>
<h3>6.6 kafka-exporter Health Check Script</h3>
<pre><code class="language-bash">#!/bin/bash
# kafka-exporter-health-check.sh

NAMESPACE=&quot;monitoring&quot;
SERVICE_NAME=&quot;kafka-exporter&quot;
METRICS_PORT=&quot;9308&quot;

echo &quot;=== kafka-exporter Health Check ===&quot;

# Check pod status
echo &quot;1. Checking pod status...&quot;
POD_STATUS=$(kubectl get pods -n $NAMESPACE -l app=$SERVICE_NAME -o jsonpath=&#39;{.items[0].status.phase}&#39;)
if [ &quot;$POD_STATUS&quot; = &quot;Running&quot; ]; then
    echo &quot;✓ Pod is running&quot;
else
    echo &quot;✗ Pod is not running: $POD_STATUS&quot;
    exit 1
fi

# Check service endpoints
echo &quot;2. Checking service endpoints...&quot;
ENDPOINTS=$(kubectl get endpoints $SERVICE_NAME -n $NAMESPACE -o jsonpath=&#39;{.subsets[0].addresses[0].ip}&#39;)
if [ -n &quot;$ENDPOINTS&quot; ]; then
    echo &quot;✓ Service has endpoints: $ENDPOINTS&quot;
else
    echo &quot;✗ Service has no endpoints&quot;
    exit 1
fi

# Test metrics endpoint
echo &quot;3. Testing metrics endpoint...&quot;
kubectl exec -n $NAMESPACE -l app=$SERVICE_NAME -- curl -s --max-time 5 localhost:$METRICS_PORT/metrics &gt; /tmp/kafka-metrics.txt
if [ $? -eq 0 ]; then
    METRIC_COUNT=$(grep -c &quot;^kafka_&quot; /tmp/kafka-metrics.txt)
    echo &quot;✓ Metrics endpoint accessible, found $METRIC_COUNT kafka metrics&quot;
else
    echo &quot;✗ Metrics endpoint not accessible&quot;
    exit 1
fi

# Check for critical metrics
echo &quot;4. Checking for critical metrics...&quot;
CRITICAL_METRICS=(&quot;kafka_brokers&quot; &quot;kafka_topic_partitions&quot; &quot;kafka_consumergroup_lag&quot;)
for metric in &quot;${CRITICAL_METRICS[@]}&quot;; do
    if grep -q &quot;$metric&quot; /tmp/kafka-metrics.txt; then
        echo &quot;✓ Found $metric&quot;
    else
        echo &quot;⚠ Missing $metric&quot;
    fi
done

# Check ServiceMonitor
echo &quot;5. Checking ServiceMonitor...&quot;
kubectl get servicemonitor $SERVICE_NAME -n $NAMESPACE &gt; /dev/null 2&gt;&amp;1
if [ $? -eq 0 ]; then
    echo &quot;✓ ServiceMonitor exists&quot;
else
    echo &quot;✗ ServiceMonitor missing&quot;
    exit 1
fi

echo &quot;=== Health check complete ===&quot;
</code></pre>
<hr>
<h2>7 End-to-End Pipeline Testing</h2>
<h3>7.1 Install awscurl (Required for AMP Querying)</h3>
<pre><code class="language-bash"># Install awscurl for querying AMP
pip install awscurl

# Alternative: Use Docker if you don&#39;t want to install Python dependencies
docker pull okigan/awscurl

# Test awscurl installation
awscurl --version
</code></pre>
<h3>7.2 Port-Forward Prometheus Agent</h3>
<pre><code class="language-bash"># Port-forward Prometheus agent for testing
kubectl -n monitoring port-forward deploy/&lt;PROMETHEUS_AGENT_DEPLOYMENT_NAME&gt; 9090:9090 &amp;
</code></pre>
<h3>7.3 Verify Metrics Collection</h3>
<pre><code class="language-bash"># Check that kafka-exporter metrics are collected by Prometheus
echo &quot;Testing kafka-exporter metrics collection...&quot;
curl -sG &#39;http://localhost:9090/api/v1/label/__name__/values&#39; \
     --data-urlencode &#39;match[]={job=&quot;kafka-exporter&quot;}&#39; | jq -r &#39;.data[]&#39; | head -10

# Check for specific kafka metrics
echo &quot;Checking for kafka consumer group lag metrics...&quot;
curl -sG &#39;http://localhost:9090/api/v1/query&#39; \
     --data-urlencode &#39;query=kafka_consumergroup_lag&#39; | jq &#39;.data.result | length&#39;

# Check for Knative metrics
echo &quot;Checking for Knative metrics...&quot;
curl -sG &#39;http://localhost:9090/api/v1/label/__name__/values&#39; \
     --data-urlencode &#39;match[]={job=~&quot;.*knative.*&quot;}&#39; | jq -r &#39;.data[]&#39; | head -5
</code></pre>
<h3>7.4 Verify Remote Write Queue Health</h3>
<pre><code class="language-bash"># Check samples being queued for remote write
echo &quot;Checking remote write queue...&quot;
curl -sG &#39;http://localhost:9090/api/v1/query&#39; \
     --data-urlencode &#39;query=prometheus_remote_storage_samples_in_total&#39; | jq &#39;.data.result&#39;

# Check samples being sent to AMP
echo &quot;Checking samples sent to AMP...&quot;
curl -sG &#39;http://localhost:9090/api/v1/query&#39; \
     --data-urlencode &#39;query=rate(prometheus_remote_storage_sent_samples_total[5m])&#39; | jq &#39;.data.result&#39;

# Check for any remote write errors
echo &quot;Checking for remote write errors...&quot;
curl -sG &#39;http://localhost:9090/api/v1/query&#39; \
     --data-urlencode &#39;query=prometheus_remote_storage_failed_samples_total&#39; | jq &#39;.data.result&#39;
</code></pre>
<h3>7.5 Test AMP Data Reception</h3>
<pre><code class="language-bash"># First, get the workspace endpoint
WORKSPACE_ID=&quot;&lt;AMP_WORKSPACE_ID&gt;&quot;
AWS_REGION=&quot;&lt;YOUR_AWS_REGION&gt;&quot;

# Get the query endpoint URL
QUERY_ENDPOINT=$(aws amp describe-workspace \
    --workspace-id $WORKSPACE_ID \
    --region $AWS_REGION \
    --query &#39;workspace.prometheusEndpoint&#39; \
    --output text)

echo &quot;Workspace endpoint: $QUERY_ENDPOINT&quot;

# Query AMP directly for kafka metrics using awscurl
echo &quot;Querying AMP directly for kafka metrics...&quot;
awscurl -X POST --region $AWS_REGION \
    --service aps \
    &quot;${QUERY_ENDPOINT}api/v1/query&quot; \
    -d &#39;query=count(kafka_consumergroup_lag{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;})&#39; \
    --header &#39;Content-Type: application/x-www-form-urlencoded&#39;

# Query for Knative metrics
echo &quot;Querying AMP for Knative metrics...&quot;
awscurl -X POST --region $AWS_REGION \
    --service aps \
    &quot;${QUERY_ENDPOINT}api/v1/query&quot; \
    -d &#39;query=count({cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;, __name__=~&quot;knative_.*&quot;})&#39; \
    --header &#39;Content-Type: application/x-www-form-urlencoded&#39;

# Alternative: Using Docker for awscurl
export WORKSPACE_ID=&quot;&lt;AMP_WORKSPACE_ID&gt;&quot;
export AWS_REGION=&quot;&lt;YOUR_AWS_REGION&gt;&quot;

QUERY_ENDPOINT=$(aws amp describe-workspace \
    --workspace-id $WORKSPACE_ID \
    --region $AWS_REGION \
    --query &#39;workspace.prometheusEndpoint&#39; \
    --output text)

docker run --rm -it \
    -e AWS_ACCESS_KEY_ID \
    -e AWS_SECRET_ACCESS_KEY \
    -e AWS_SESSION_TOKEN \
    okigan/awscurl \
    --region $AWS_REGION \
    --service aps \
    &quot;${QUERY_ENDPOINT}api/v1/query&quot; \
    -d &#39;query=up{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}&#39; \
    --header &#39;Content-Type: application/x-www-form-urlencoded&#39;
</code></pre>
<hr>
<h2>8 Grafana Integration and Validation</h2>
<h3>8.1 Configure Grafana Data Source</h3>
<ol>
<li><strong>Open Grafana</strong> → <strong>Configuration</strong> → <strong>Data Sources</strong> → <strong>Add data source</strong></li>
<li><strong>Select</strong> → <strong>Amazon Managed Prometheus</strong></li>
<li><strong>Configure</strong>:<ul>
<li><strong>Name</strong>: <code>AMP-Knative-Kafka</code></li>
<li><strong>Workspace ID</strong>: <code>&lt;AMP_WORKSPACE_ID&gt;</code></li>
<li><strong>Region</strong>: <code>&lt;YOUR_AWS_REGION&gt;</code></li>
<li><strong>Authentication</strong>: <code>AWS SigV4</code></li>
<li><strong>Default Region</strong>: <code>&lt;YOUR_AWS_REGION&gt;</code></li>
</ul>
</li>
<li><strong>Click</strong> → <strong>Save &amp; Test</strong> (should show &quot;Data source is working&quot;)</li>
</ol>
<h3>8.2 Test Grafana Queries</h3>
<pre><code class="language-promql"># Test basic connectivity
up{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}

# Test kafka metrics
kafka_consumergroup_lag{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}

# Test Knative metrics
rate(knative_broker_events_total{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}[5m])

# Test aggregated metrics
sum(kafka_consumergroup_lag{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}) by (consumergroup)
</code></pre>
<h3>8.3 Create Sample Dashboard</h3>
<pre><code class="language-json">{
  &quot;dashboard&quot;: {
    &quot;title&quot;: &quot;Kafka &amp; Knative Metrics&quot;,
    &quot;panels&quot;: [
      {
        &quot;title&quot;: &quot;Kafka Consumer Group Lag&quot;,
        &quot;type&quot;: &quot;graph&quot;,
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;kafka_consumergroup_lag{cluster=\&quot;&lt;YOUR_CLUSTER_NAME&gt;\&quot;}&quot;,
            &quot;legendFormat&quot;: &quot;{{consumergroup}} - {{topic}}&quot;
          }
        ]
      },
      {
        &quot;title&quot;: &quot;Knative Broker Events Rate&quot;,
        &quot;type&quot;: &quot;graph&quot;, 
        &quot;targets&quot;: [
          {
            &quot;expr&quot;: &quot;rate(knative_broker_events_total{cluster=\&quot;&lt;YOUR_CLUSTER_NAME&gt;\&quot;}[5m])&quot;,
            &quot;legendFormat&quot;: &quot;{{broker}} - {{event_type}}&quot;
          }
        ]
      }
    ]
  }
}
</code></pre>
<hr>
<h2>9 Comprehensive Troubleshooting Guide</h2>
<h3>9.1 Common Issues and Solutions</h3>
<h4>Issue: kafka-exporter Not Collecting Metrics</h4>
<p><strong>Symptoms</strong>: No kafka metrics in Prometheus, web interface shows connection errors<br><strong>Diagnostics</strong>:</p>
<pre><code class="language-bash"># Check pod logs
kubectl logs -n monitoring -l app=kafka-exporter

# Check Kafka connectivity
kubectl exec -n monitoring -l app=kafka-exporter -- nc -zv &lt;kafka-broker&gt; 9092

# Test authentication
kubectl exec -n monitoring -l app=kafka-exporter -- kafkacat -b &lt;kafka-broker&gt;:9092 -L
</code></pre>
<h4>Issue: ServiceMonitor Not Discovered</h4>
<p><strong>Symptoms</strong>: Targets not showing up in Prometheus<br><strong>Diagnostics</strong>:</p>
<pre><code class="language-bash"># Check ServiceMonitor labels
kubectl get servicemonitor kafka-exporter -n monitoring -o yaml

# Check if Prometheus can access ServiceMonitor
kubectl get servicemonitor -A --show-labels
</code></pre>
<h4>Issue: Remote Write Failures</h4>
<p><strong>Symptoms</strong>: Metrics in Prometheus but not in AMP<br><strong>Diagnostics</strong>:</p>
<pre><code class="language-bash"># Check IAM permissions
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus | grep -i &quot;sigv4\|remote_write\|401\|403&quot;

# Test AMP connectivity
kubectl run amp-test --rm -it --restart=Never --image=curlimages/curl -- \
  curl -v https://aps-workspaces.&lt;YOUR_AWS_REGION&gt;.amazonaws.com/workspaces/&lt;AMP_WORKSPACE_ID&gt;/api/v1/remote_write
</code></pre>
<h3>9.2 Useful Debugging Commands</h3>
<pre><code class="language-bash"># List all ServiceMonitors
kubectl get servicemonitor -A

# Check Prometheus targets
curl -s localhost:9090/api/v1/targets | jq &#39;.data.activeTargets[] | select(.labels.job == &quot;kafka-exporter&quot;)&#39;

# Check queue health
curl -s localhost:9090/api/v1/query?query=prometheus_remote_storage_pending_samples | jq .

# Check network connectivity
kubectl run netcheck --rm -it --restart=Never --image=busybox -- \
  nc -zv kafka-exporter.monitoring.svc.cluster.local 9308
</code></pre>
<h3>9.3 Performance Monitoring</h3>
<pre><code class="language-bash"># Monitor remote write performance
curl -s localhost:9090/api/v1/query?query=rate(prometheus_remote_storage_sent_samples_total[5m]) | jq .

# Check scrape duration
curl -s localhost:9090/api/v1/query?query=scrape_duration_seconds | jq .

# Monitor memory usage
kubectl top pods -n monitoring
</code></pre>
<hr>
<h2>10 Maintenance and Monitoring</h2>
<h3>10.1 Regular Health Checks</h3>
<pre><code class="language-bash"># Weekly health check script
#!/bin/bash
echo &quot;=== Weekly Metrics Pipeline Health Check ===&quot;

# Check all components
kubectl get pods -n monitoring | grep -E &quot;prometheus|kafka-exporter&quot;

# Check AMP workspace
aws amp describe-workspace --workspace-id &lt;AMP_WORKSPACE_ID&gt; --region &lt;YOUR_AWS_REGION&gt;

# Test end-to-end flow with awscurl
QUERY_ENDPOINT=$(aws amp describe-workspace \
    --workspace-id &lt;AMP_WORKSPACE_ID&gt; \
    --region &lt;YOUR_AWS_REGION&gt; \
    --query &#39;workspace.prometheusEndpoint&#39; \
    --output text)

awscurl -X POST --region &lt;YOUR_AWS_REGION&gt; \
    --service aps \
    &quot;${QUERY_ENDPOINT}api/v1/query&quot; \
    -d &#39;query=up{cluster=&quot;&lt;YOUR_CLUSTER_NAME&gt;&quot;}&#39; \
    --header &#39;Content-Type: application/x-www-form-urlencoded&#39;
</code></pre>
<h3>10.2 Alerting Rules</h3>
<pre><code class="language-yaml"># prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kafka-knative-alerts
  namespace: monitoring
spec:
  groups:
  - name: kafka
    rules:
    - alert: KafkaConsumerGroupLag
      expr: kafka_consumergroup_lag &gt; 1000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: &quot;Kafka consumer group lag is high&quot;
        description: &quot;Consumer group {{ $labels.consumergroup }} has lag of {{ $value }}&quot;
  
  - name: knative
    rules:
    - alert: KnativeBrokerDown
      expr: up{job=~&quot;.*knative.*&quot;} == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: &quot;Knative broker is down&quot;
</code></pre>
<hr>

</body>
</html>